{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# DerivKit — CalculusKit Demo (advanced analytic: gradient, Hessian, Jacobian)\n",
    "\n",
    "This notebook uses a more complex scalar function (exp/trig/poly/log mix) and a\n",
    "richer vector function, both with closed-form derivatives, to validate\n",
    "**CalculusKit**’s adaptive derivatives against analytic truth.\n",
    "\n",
    "#### Functions\n",
    "\n",
    "**Scalar**\n",
    "$f(x_1, x_2) \\;=\\; e^{x_1}\\sin x_2 \\;+\\; \\tfrac12 x_1^2 x_2^3 \\;-\\; \\ln(1 + x_1^2 + x_2^2)$\n",
    "\n",
    "**Vector**\n",
    "$g(x_1, x_2) = \\begin{bmatrix}\n",
    "e^{x_1}\\cos x_2 + x_1 x_2^2\\\\\n",
    "x_1^2 x_2 + \\sin(x_1 x_2)\\\\\n",
    "\\ln(1 + x_1^2 x_2^2) + \\cosh x_1 - \\sinh x_2\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### What it does\n",
    "\n",
    "- Sets $x_0 = [0.7,\\,-1.2]$.\n",
    "- Computes:\n",
    "  - $\\nabla f$ and $H$ with **adaptive** derivatives.\n",
    "  - $J$ for the vector function with **adaptive** derivatives.\n",
    "- Prints numeric vs analytic results and their deltas.\n",
    "\n",
    "### Notes:\n",
    "- The adaptive backend automatically selects a local grid size for stable polynomial fits.\n",
    "- All derivative routines support multi-dimensional inputs and arbitrary scalar/vector outputs.\n",
    "- Use small test functions to verify correctness before applying to complex models.\n",
    "\n",
    "### Requirements\n",
    "- `derivkit` installed and importable in your Python environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from derivkit.calculus_kit import CalculusKit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Test functions and analytic references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_scalar_function(x: np.ndarray) -> float:\n",
    "    \"\"\"Scalar function f: R^2 -> R with mixed nonlinearity.\"\"\"\n",
    "    x1, x2 = float(x[0]), float(x[1])\n",
    "    return (\n",
    "        np.exp(x1) * np.sin(x2)\n",
    "        + 0.5 * x1**2 * x2**3\n",
    "        - np.log(1.0 + x1**2 + x2**2)\n",
    "    )\n",
    "\n",
    "\n",
    "def g_vector_function(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Vector function g: R^2 -> R^3 with mixed nonlinearity.\"\"\"\n",
    "    x1, x2 = float(x[0]), float(x[1])\n",
    "    return np.array(\n",
    "        [\n",
    "            np.exp(x1) * np.cos(x2) + x1 * x2**2,\n",
    "            x1**2 * x2 + np.sin(x1 * x2),\n",
    "            np.log(1.0 + x1**2 * x2**2) + np.cosh(x1) - np.sinh(x2),\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "\n",
    "def f_grad_analytic(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Analytic gradient of f.\"\"\"\n",
    "    x1, x2 = float(x[0]), float(x[1])\n",
    "    denom = 1.0 + x1**2 + x2**2\n",
    "    dfdx1 = np.exp(x1) * np.sin(x2) + x1 * x2**3 - 2.0 * x1 / denom\n",
    "    dfdx2 = np.exp(x1) * np.cos(x2) + 1.5 * x1**2 * x2**2 - 2.0 * x2 / denom\n",
    "    return np.array([dfdx1, dfdx2], dtype=float)\n",
    "\n",
    "\n",
    "def f_hess_analytic(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Analytic Hessian of f.\"\"\"\n",
    "    x1, x2 = float(x[0]), float(x[1])\n",
    "    q = x1**2 + x2**2\n",
    "    denom = 1.0 + q\n",
    "    denom2 = denom**2\n",
    "\n",
    "    dxx = np.exp(x1) * np.sin(x2) + x2**3 - 2.0 / denom + 4.0 * x1**2 / denom2\n",
    "    dxy = np.exp(x1) * np.cos(x2) + 3.0 * x1 * x2**2 + 4.0 * x1 * x2 / denom2\n",
    "    dyy = -np.exp(x1) * np.sin(x2) + 3.0 * x1**2 * x2 - 2.0 / denom + 4.0 * x2**2 / denom2\n",
    "\n",
    "    return np.array([[dxx, dxy], [dxy, dyy]], dtype=float)\n",
    "\n",
    "\n",
    "def g_jac_analytic(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Analytic Jacobian of g; shape (3 outputs, 2 params).\"\"\"\n",
    "    x1, x2 = float(x[0]), float(x[1])\n",
    "\n",
    "    # Row 1: h1 = exp(x1)*cos(x2) + x1*x2^2\n",
    "    dh1_dx1 = np.exp(x1) * np.cos(x2) + x2**2\n",
    "    dh1_dx2 = -np.exp(x1) * np.sin(x2) + 2.0 * x1 * x2\n",
    "\n",
    "    # Row 2: h2 = x1^2 * x2 + sin(x1*x2)\n",
    "    dh2_dx1 = 2.0 * x1 * x2 + np.cos(x1 * x2) * x2\n",
    "    dh2_dx2 = x1**2 + np.cos(x1 * x2) * x1\n",
    "\n",
    "    # Row 3: h3 = log(1 + x1^2 x2^2) + cosh(x1) - sinh(x2)\n",
    "    r = 1.0 + x1**2 * x2**2\n",
    "    dh3_dx1 = (2.0 * x1 * x2**2) / r + np.sinh(x1)\n",
    "    dh3_dx2 = (2.0 * x2 * x1**2) / r - np.cosh(x2)\n",
    "\n",
    "    return np.array(\n",
    "        [\n",
    "            [dh1_dx1, dh1_dx2],\n",
    "            [dh2_dx1, dh2_dx2],\n",
    "            [dh3_dx1, dh3_dx2],\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Helpers for printing and error summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(name: str, arr: np.ndarray) -> None:\n",
    "    \"\"\"Pretty-print an array with a name.\"\"\"\n",
    "    print(f\"{name}:\\n{np.array(arr, dtype=float)}\\n\")\n",
    "\n",
    "\n",
    "def show_delta(name: str, a: np.ndarray, b: np.ndarray) -> None:\n",
    "    \"\"\"Computes and prints the difference between two arrays.\"\"\"\n",
    "    a = np.array(a, dtype=float)\n",
    "    b = np.array(b, dtype=float)\n",
    "    diff = a - b\n",
    "    eps = 1e-15\n",
    "    denom = np.maximum(1.0, np.abs(b)) + eps\n",
    "    rel_elem = np.abs(diff) / denom\n",
    "    rel_max = np.max(rel_elem)\n",
    "    rel_rms = np.sqrt(np.mean(rel_elem**2))\n",
    "    print(f\"{name} delta (num - analytic):\")\n",
    "    print(diff)\n",
    "    print(f\"  max rel err = {rel_max:.3e},  rms rel err = {rel_rms:.3e}\")\n",
    "    print(f\"  max|Δ| = {np.max(np.abs(diff)):.3e},  ||Δ||₂ = {np.linalg.norm(diff):.3e}\\n\")\n",
    "\n",
    "\n",
    "def brief(name: str, num: np.ndarray, ref: np.ndarray) -> None:\n",
    "    \"\"\"One-line summary with max absolute deviation.\"\"\"\n",
    "    d = np.linalg.norm(np.ravel(num - ref), ord=np.inf)\n",
    "    print(f\"{name}: max|Δ| = {d:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Run examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation point\n",
    "x0 = np.array([0.7, -1.2], dtype=float)\n",
    "print(\"=== CalculusKit advanced demo at x0 =\", x0, \"===\\n\")\n",
    "\n",
    "# Instantiate CalculusKit for each function\n",
    "calc_f = CalculusKit(f_scalar_function, x0=x0)\n",
    "calc_g = CalculusKit(g_vector_function, x0=x0)\n",
    "\n",
    "# Scalar: gradient & Hessian\n",
    "grad_num = calc_f.gradient(method=\"adaptive\")\n",
    "hess_num = calc_f.hessian(method=\"adaptive\")\n",
    "\n",
    "grad_ref = f_grad_analytic(x0)\n",
    "hess_ref = f_hess_analytic(x0)\n",
    "\n",
    "pretty_print(\"∇f (numeric)\", grad_num)\n",
    "pretty_print(\"∇f (analytic)\", grad_ref)\n",
    "show_delta(\"∇f\", grad_num, grad_ref)\n",
    "\n",
    "pretty_print(\"H (numeric)\", hess_num)\n",
    "pretty_print(\"H (analytic)\", hess_ref)\n",
    "show_delta(\"H\", hess_num, hess_ref)\n",
    "\n",
    "# Vector: Jacobian\n",
    "jac_num = calc_g.jacobian(method=\"adaptive\")\n",
    "jac_ref = g_jac_analytic(x0)\n",
    "\n",
    "pretty_print(\"J (numeric)\", jac_num)\n",
    "pretty_print(\"J (analytic)\", jac_ref)\n",
    "show_delta(\"J\", jac_num, jac_ref)\n",
    "\n",
    "# Brief summaries\n",
    "brief(\"∇f\", grad_num, grad_ref)\n",
    "brief(\"H\",  hess_num, hess_ref)\n",
    "brief(\"J\",  jac_num,  jac_ref)\n",
    "\n",
    "print(\"Done. ∇ guides, H bends, J translates.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "\n",
    "## Optional: Compare with the finite-difference backend\n",
    "\n",
    "Uncomment the cell below to compare the **finite** backend against analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run a finite-difference cross-check\n",
    "# grad_fi = calc_f.gradient(method=\"finite\")\n",
    "# hess_fi = calc_f.hessian(method=\"finite\")\n",
    "# jac_fi  = calc_g.jacobian(method=\"finite\")\n",
    "# show_delta(\"∇f (finite - analytic)\", grad_fi, grad_ref)\n",
    "# show_delta(\"H   (finite - analytic)\", hess_fi, hess_ref)\n",
    "# show_delta(\"J   (finite - analytic)\", jac_fi,  jac_ref)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
